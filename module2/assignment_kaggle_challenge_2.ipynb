{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IXUfiQ2UKj6"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Kaggle Challenge, Module 2\n",
    "\n",
    "## Assignment\n",
    "- [ ] Read [“Adopting a Hypothesis-Driven Workflow”](https://outline.com/5S5tsB), a blog post by a Lambda DS student about the Tanzania Waterpumps challenge.\n",
    "- [ ] Continue to participate in our Kaggle challenge.\n",
    "- [ ] Try Ordinal Encoding.\n",
    "- [ ] Try a Random Forest Classifier.\n",
    "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
    "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "### Doing\n",
    "- [ ] Add your own stretch goal(s) !\n",
    "- [ ] Do more exploratory data analysis, data cleaning, feature engineering, and feature selection.\n",
    "- [ ] Try other [categorical encodings](https://contrib.scikit-learn.org/categorical-encoding/).\n",
    "- [ ] Get and plot your feature importances.\n",
    "- [ ] Make visualizations and share on Slack.\n",
    "\n",
    "### Reading\n",
    "\n",
    "Top recommendations in _**bold italic:**_\n",
    "\n",
    "#### Decision Trees\n",
    "- A Visual Introduction to Machine Learning, [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/),  and _**[Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)**_\n",
    "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
    "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
    "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
    "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU)\n",
    "\n",
    "#### Random Forests\n",
    "- [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/), Chapter 8: Tree-Based Methods\n",
    "- [Coloring with Random Forests](http://structuringtheunstructured.blogspot.com/2017/11/coloring-with-random-forests.html)\n",
    "- _**[Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)**_\n",
    "\n",
    "#### Categorical encoding for trees\n",
    "- [Are categorical variables getting lost in your random forests?](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)\n",
    "- [Beyond One-Hot: An Exploration of Categorical Variables](http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/)\n",
    "- _**[Categorical Features and Encoding in Decision Trees](https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931)**_\n",
    "- _**[Coursera — How to Win a Data Science Competition: Learn from Top Kagglers — Concept of mean encoding](https://www.coursera.org/lecture/competitive-data-science/concept-of-mean-encoding-b5Gxv)**_\n",
    "- [Mean (likelihood) encodings: a comprehensive study](https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n",
    "- [The Mechanics of Machine Learning, Chapter 6: Categorically Speaking](https://mlbook.explained.ai/catvars.html)\n",
    "\n",
    "#### Imposter Syndrome\n",
    "- [Effort Shock and Reward Shock (How The Karate Kid Ruined The Modern World)](http://www.tempobook.com/2014/07/09/effort-shock-and-reward-shock/)\n",
    "- [How to manage impostor syndrome in data science](https://towardsdatascience.com/how-to-manage-impostor-syndrome-in-data-science-ad814809f068)\n",
    "- [\"I am not a real data scientist\"](https://brohrer.github.io/imposter_syndrome.html)\n",
    "- _**[Imposter Syndrome in Data Science](https://caitlinhudon.com/2018/01/19/imposter-syndrome-in-data-science/)**_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9eSnDYhUGD7"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "# If you're in Colab...\n",
    "if in_colab:\n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Install required python packages\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJBD4ruICm1m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
    "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
    "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
    "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
    "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangle (setup) train, validated, and test sets\"\"\"\n",
    "    \n",
    "    X = X.copy()\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    cols_with_zeroes = ['longitude', 'latitude', 'construction_year',\n",
    "                       'gps_height', 'population']\n",
    "    # storing the missing values in another column in case that's useful.\n",
    "    # impute the missing values later.\n",
    "    for col in cols_with_zeroes:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "    \n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # unusuable variance or otherwise seemingly unfit data\n",
    "    #   dropping the other columns didn't seem to do much unfortuntaley\n",
    "    unusable_variance = ['recorded_by', 'id', 'amount_tsh', 'public_meeting', 'scheme_name', 'subvillage', 'ward',\n",
    "                        'num_private', 'lga']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "        \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'status_group'\n",
    "train_features = train.drop(columns=[target])\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
    "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
    "features = numeric_features + categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector \n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.807996632996633\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred\n",
    "submission.to_csv('submission-03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\school\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression, Validation Accuracy 0.7375420875420875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "# Comparing to Logistic Regression with OneHotEncoding\n",
    "lr = make_pipeline(\n",
    "    ce.OneHotEncoder(use_cat_names=True), \n",
    "    SimpleImputer(), \n",
    "    StandardScaler(), \n",
    "    LogisticRegressionCV(multi_class='auto', solver='lbfgs', cv=5, n_jobs=-1)\n",
    ")\n",
    "\n",
    "lr.fit(X_train[features], y_train)\n",
    "score = lr.score(X_val[features], y_val)\n",
    "print('Logistic Regression, Validation Accuracy', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting some of the other stuff in the lesson.\n",
    "import matplotlib.pyplot as plt\n",
    "encoder = pipeline.named_steps['ordinalencoder']\n",
    "encoded = encoder.transform(X_train)\n",
    "rf = pipeline.named_steps['randomforestclassifier']\n",
    "importances = pd.Series(rf.feature_importances_, encoded.columns)\n",
    "\n",
    "plt.figure(figsize=(10,10/2))\n",
    "plt.title('Top 10 features')\n",
    "importances.sort_values()[-10:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "feature = 'extraction_type_class'\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.barplot(\n",
    "    x=train[feature], \n",
    "    y=train['status_group']=='functional', \n",
    "    color='grey'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "putts = pd.DataFrame(\n",
    "    columns=['distance', 'tries', 'successes'], \n",
    "    data = [[2, 1443, 1346],\n",
    "            [3, 694, 577],\n",
    "            [4, 455, 337],\n",
    "            [5, 353, 208],\n",
    "            [6, 272, 149],\n",
    "            [7, 256, 136],\n",
    "            [8, 240, 111],\n",
    "            [9, 217, 69],\n",
    "            [10, 200, 67],\n",
    "            [11, 237, 75],\n",
    "            [12, 202, 52],\n",
    "            [13, 192, 46],\n",
    "            [14, 174, 54],\n",
    "            [15, 167, 28],\n",
    "            [16, 201, 27],\n",
    "            [17, 195, 31],\n",
    "            [18, 191, 33],\n",
    "            [19, 147, 20],\n",
    "            [20, 152, 24]]\n",
    ")\n",
    "\n",
    "putts['rate of success'] = putts['successes'] / putts['tries']\n",
    "putts_X = putts[['distance']]\n",
    "putts_y = putts['rate of success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-421545127f2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mensembled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minteract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiy_bagging\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mputts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# DecisisionTreeRegressor\n",
    "def diy_bagging(df, max_depth=1, n_estimators=1):\n",
    "    y_preds = []\n",
    "    for i in range(n_estimators):\n",
    "        title = f'Tree {i+1}'\n",
    "        bootstrap_sample = df.sample(n=len(df), replace=True).sort_values(by='distance')\n",
    "        bootstrap_X = bootstrap_sample[['distance']]\n",
    "        bootstrap_y = bootstrap_sample['rate of success']\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        tree.fit(bootstrap_X, bootstrap_y)\n",
    "        y_pred = tree.predict(bootstrap_X)\n",
    "        y_preds.append(y_pred)\n",
    "       # ax = bootstrap_sample.plot('distance', 'rate of success', kind='scatter', title=title)\n",
    "       # ax.step(bootstrap_X, y_pred, where='mid')\n",
    "       # plt.show()\n",
    "        \n",
    "    ensembled = np.vstack(y_preds).mean(axis=0)\n",
    "    title = f'Ensemble of {n_estimators} trees, with max_depth={max_depth}'\n",
    "    # ax = putts.plot('distance', 'rate of success', kind='scatter', title=title)\n",
    "    # ax.step(putts_X, ensembled, where='mid')\n",
    "    # plt.show()\n",
    "    return ensembled\n",
    "    \n",
    "y_pred = interact(diy_bagging, putts, max_depth=(1,6,1), n_estimators=(2,50,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diy_bagging(putts, max_depth=4, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_kaggle_challenge_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
